

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Overview &mdash; StarDist  documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://stardist.net/docs/index.html"/>
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Frequently Asked Questions (FAQ)" href="faq.html" />
    <link rel="prev" title="StarDist" href="../index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> StarDist
          

          
            
            <img src="../_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#webinar-tutorial">Webinar/Tutorial</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#installation">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#notes">Notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="#troubleshooting">Troubleshooting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#macos">macOS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#windows">Windows</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#usage">Usage</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#pretrained-models-for-2d">Pretrained Models for 2D</a></li>
<li class="toctree-l2"><a class="reference internal" href="#annotating-images">Annotating Images</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#annotating-with-labkit-2d-or-3d">Annotating with LabKit (2D or 3D)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#annotating-with-qupath-2d">Annotating with QuPath (2D)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#imagej-fiji-plugin">ImageJ/Fiji Plugin</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">Frequently Asked Questions (FAQ)</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">StarDist</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Overview</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="overview">
<h1>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h1>
<p>The following figure illustrates the general approach for 2D images. The training data consists of corresponding pairs of input (i.e. raw) images and fully annotated label images (i.e. every pixel is labeled with a unique object id or 0 for background).
A model is trained to densely predict the distances (r) to the object boundary along a fixed set of rays and object probabilities (d), which together produce an overcomplete set of candidate polygons for a given input image. The final result is obtained via non-maximum supression (NMS) of these candidates.</p>
<p><img alt="https://github.com/mpicbg-csbd/stardist/raw/master/images/overview_2d.png" src="https://github.com/mpicbg-csbd/stardist/raw/master/images/overview_2d.png" /></p>
<p>The approach for 3D volumes is similar to the one described for 2D, using pairs of input and fully annotated label volumes as training data.</p>
<p><img alt="https://github.com/mpicbg-csbd/stardist/raw/master/images/overview_3d.png" src="https://github.com/mpicbg-csbd/stardist/raw/master/images/overview_3d.png" /></p>
<div class="section" id="webinar-tutorial">
<h2>Webinar/Tutorial<a class="headerlink" href="#webinar-tutorial" title="Permalink to this headline">¶</a></h2>
<p>If you want to know more about the concepts and practical applications of StarDist, please have a look at the following webinar that was given at NEUBIAS Academy &#64;Home 2020:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Amn_eHRGX5M" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<br>&nbsp;</div>
</div>
<div class="section" id="installation">
<h1>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h1>
<p>This package requires Python 3.5 (or newer).</p>
<p>Please first <a class="reference external" href="https://www.tensorflow.org/install">install TensorFlow 1.x</a>
by following the official instructions. (<strong>Do not choose TensorFlow 2.x</strong>)
For <a class="reference external" href="https://www.tensorflow.org/install/gpu">GPU support</a>, it is very
important to install the specific versions of CUDA and cuDNN that are
compatible with the respective version of TensorFlow.</p>
<p><em>StarDist</em> can then be installed with <code class="docutils literal notranslate"><span class="pre">pip</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">stardist</span>
</pre></div>
</div>
<div class="section" id="notes">
<h2>Notes<a class="headerlink" href="#notes" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Depending on your Python installation, you may need to use <code class="docutils literal notranslate"><span class="pre">pip3</span></code> instead of <code class="docutils literal notranslate"><span class="pre">pip</span></code>.</p></li>
<li><p>Since this package relies on a C++ extension, you could run into compilation problems (see <a class="reference external" href="#troubleshooting">Troubleshooting</a> below). We currently do not provide pre-compiled binaries.</p></li>
<li><p>StarDist uses the deep learning library <a class="reference external" href="https://keras.io">Keras</a>, which requires a suitable <a class="reference external" href="https://keras.io/backend/#keras-backends">backend</a> (we currently only support <a class="reference external" href="http://www.tensorflow.org/">TensorFlow</a>).</p></li>
<li><p><em>(Optional)</em> You need to install <a class="reference external" href="https://github.com/maweigert/gputools">gputools</a> if you want to use OpenCL-based computations on the GPU to speed up training.</p></li>
<li><p><em>(Optional)</em> You might experience improved performance during training if you additionally install the <a class="reference external" href="https://github.com/seung-lab/euclidean-distance-transform-3d">Multi-Label Anisotropic 3D Euclidean Distance Transform (MLAEDT-3D)</a>.</p></li>
</ul>
</div>
<div class="section" id="troubleshooting">
<h2>Troubleshooting<a class="headerlink" href="#troubleshooting" title="Permalink to this headline">¶</a></h2>
<p>Installation requires Python 3.5 (or newer) and a working C++ compiler. We have only tested <a class="reference external" href="http://gcc.gnu.org">GCC</a> (macOS, Linux), <a class="reference external" href="https://clang.llvm.org">Clang</a> (macOS), and <a class="reference external" href="https://visualstudio.microsoft.com">Visual Studio</a> (Windows 10). Please <a class="reference external" href="https://github.com/mpicbg-csbd/stardist/issues">open an issue</a> if you have problems that are not resolved by the information below.</p>
<p>If available, the C++ code will make use of <a class="reference external" href="https://en.wikipedia.org/wiki/OpenMP">OpenMP</a> to exploit multiple CPU cores for substantially reduced runtime on modern CPUs. This can be important to prevent slow model training.</p>
<div class="section" id="macos">
<h3>macOS<a class="headerlink" href="#macos" title="Permalink to this headline">¶</a></h3>
<p>The default Apple C/C++ compiler (<code class="docutils literal notranslate"><span class="pre">clang</span></code>) does not come with OpenMP support and the package build will likely fail.
To properly build <code class="docutils literal notranslate"><span class="pre">stardist</span></code> you need to install a OpenMP-enabled GCC compiler, e.g. via <a class="reference external" href="https://brew.sh">Homebrew</a> with <code class="docutils literal notranslate"><span class="pre">brew</span> <span class="pre">install</span> <span class="pre">gcc</span></code> (which will currently install <code class="docutils literal notranslate"><span class="pre">gcc-9</span></code>/<code class="docutils literal notranslate"><span class="pre">g++-9</span></code>). After that, you can build the package like this (adjust compiler names/paths as necessary):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">CC</span><span class="o">=</span><span class="n">gcc</span><span class="o">-</span><span class="mi">9</span> <span class="n">CXX</span><span class="o">=</span><span class="n">g</span><span class="o">++-</span><span class="mi">9</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">stardist</span>
</pre></div>
</div>
<p>If you use <code class="docutils literal notranslate"><span class="pre">conda</span></code> on macOS and after <code class="docutils literal notranslate"><span class="pre">import</span> <span class="pre">stardist</span></code> see errors similar to the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Symbol</span> <span class="ow">not</span> <span class="n">found</span><span class="p">:</span> <span class="n">_GOMP_loop_nonmonotonic_dynamic_next</span>
</pre></div>
</div>
<p>please see <a class="reference external" href="https://github.com/mpicbg-csbd/stardist/issues/19#issuecomment-535610758">this issue</a> for a temporay workaround.</p>
</div>
<div class="section" id="windows">
<h3>Windows<a class="headerlink" href="#windows" title="Permalink to this headline">¶</a></h3>
<p>Please install the <a class="reference external" href="https://www.visualstudio.com/downloads/#build-tools-for-visual-studio-2019">Build Tools for Visual Studio 2019</a> from Microsoft to compile extensions for Python 3.5 and newer (see <a class="reference external" href="https://wiki.python.org/moin/WindowsCompilers">this</a> for further information). During installation, make sure to select the <em>C++ build tools</em>. Note that the compiler comes with OpenMP support.</p>
</div>
</div>
</div>
<div class="section" id="usage">
<h1>Usage<a class="headerlink" href="#usage" title="Permalink to this headline">¶</a></h1>
<p>We provide example workflows for 2D and 3D via Jupyter <a class="reference external" href="https://github.com/mpicbg-csbd/stardist/tree/master/examples">notebooks</a> that illustrate how this package can be used.</p>
<p><img alt="https://github.com/mpicbg-csbd/stardist/raw/master/images/example_steps.png" src="https://github.com/mpicbg-csbd/stardist/raw/master/images/example_steps.png" /></p>
<div class="section" id="pretrained-models-for-2d">
<h2>Pretrained Models for 2D<a class="headerlink" href="#pretrained-models-for-2d" title="Permalink to this headline">¶</a></h2>
<p>Currently we provide some pretrained models in 2D that might already be suitable for your images:</p>
<table border="1">
<thead>
<tr>
<th style="padding: 5px" align="center">Key (Name)</th>
<th style="padding: 5px" align="center">Modality (Staining)</th>
<th style="padding: 5px" align="center">Image Format</th>
<th style="padding: 5px" align="center">Example Image</th>
<th style="padding: 5px" align="center">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="padding: 5px" align="center"><code>2D_versatile_fluo</code><br/> <code>2D_paper_dsb2018</code></td>
<td style="padding: 5px" align="center">Fluorescence (nuclear marker)</td>
<td style="padding: 5px" align="center">2D single channel</td>
<td style="padding: 5px" align="center"><img src="https://github.com/mpicbg-csbd/stardist/raw/master/images/example_fluo.jpg" title="example image fluo" width="120px" align="center" style="max-width:100%;"></td>
<td style="padding: 5px" align="center"><em>Versatile (fluorescent nuclei)</em> and <em>DSB 2018 (from StarDist 2D paper)</em> that were both trained on a subset of the <a href="https://data.broadinstitute.org/bbbc/BBBC038/">DSB 2018 nuclei segmentation challenge dataset</a>.</td>
</tr>
<tr>
<td style="padding: 5px" align="center"><code>2D_versatile_he</code></td>
<td style="padding: 5px" align="center">Brightfield (H&amp;E)</td>
<td style="padding: 5px" align="center">2D RGB</td>
<td style="padding: 5px" align="center"><img src="https://github.com/mpicbg-csbd/stardist/raw/master/images/example_histo.jpg" title="example image histo" width="120px" align="center" style="max-width:100%;"></td>
<td style="padding: 5px" align="center"><em>Versatile (H&amp;E nuclei)</em> that was trained on images from the <a href="https://monuseg.grand-challenge.org/Data/">MoNuSeg 2018 training data</a> and the <a href="http://cancergenome.nih.gov/">TCGA archive</a>.</td>
</tr>
</tbody>
</table>
<br/><!--
| key | Modality (Staining) | Image format | Example Image    | Description  | 
| :-- | :-: | :-:| :-:| :-- |
| `2D_versatile_fluo` `2D_paper_dsb2018`| Fluorescence (nuclear marker) | 2D single channel| <img src="https://github.com/mpicbg-csbd/stardist/raw/master/images/example_fluo.jpg" title="example image fluo" width="120px" align="center">       | *Versatile (fluorescent nuclei)* and *DSB 2018 (from StarDist 2D paper)* that were both trained on a subset of the [ DSB 2018 nuclei segmentation challenge dataset](https://data.broadinstitute.org/bbbc/BBBC038/). | 
|`2D_versatile_he` | Brightfield (H&E) | 2D RGB  | <img src="https://github.com/mpicbg-csbd/stardist/raw/master/images/example_histo.jpg" title="example image histo" width="120px" align="center">       | *Versatile (H&E nuclei)* that was trained on images from the [MoNuSeg 2018 training data](https://monuseg.grand-challenge.org/Data/) and the [TCGA archive](http://cancergenome.nih.gov/). |
--><p>You can access these pretrained models from <code class="docutils literal notranslate"><span class="pre">stardist.models.StarDist2D</span></code></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stardist.models</span> <span class="kn">import</span> <span class="n">StarDist2D</span> 

<span class="c1"># prints a list of available models </span>
<span class="n">StarDist2D</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">()</span> 

<span class="c1"># creates a pretrained model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">StarDist2D</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;2D_versatile_fluo&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="annotating-images">
<h2>Annotating Images<a class="headerlink" href="#annotating-images" title="Permalink to this headline">¶</a></h2>
<p>To train a <em>StarDist</em> model you will need some ground-truth annotations: for every raw training image there has to be a corresponding label image where all pixels of a cell region are labeled with a distinct integer (and background pixels are labeled with 0).
To create such annotations in 2D, there are several options, among them being <a class="reference external" href="http://fiji.sc/">Fiji</a>, <a class="reference external" href="https://imagej.net/Labkit">Labkit</a>, or <a class="reference external" href="https://qupath.github.io">QuPath</a>. In 3D, there are fewer options: <a class="reference external" href="https://github.com/maarzt/imglib2-labkit">Labkit</a> and <a class="reference external" href="https://github.com/saalfeldlab/paintera">Paintera</a> (the latter being very sophisticated but having a steeper learning curve).</p>
<p>Although each of these provide decent annotation tools, we currently recommend using Labkit (for 2D or 3D images) or QuPath (for 2D):</p>
<div class="section" id="annotating-with-labkit-2d-or-3d">
<h3>Annotating with LabKit (2D or 3D)<a class="headerlink" href="#annotating-with-labkit-2d-or-3d" title="Permalink to this headline">¶</a></h3>
<ol class="simple">
<li><p>Install <a class="reference external" href="https://fiji.sc">Fiji</a> and the <a class="reference external" href="https://imagej.net/Labkit">Labkit</a> plugin</p></li>
<li><p>Open the (2D or 3D) image and start Labkit via <code class="docutils literal notranslate"><span class="pre">Plugins</span> <span class="pre">&gt;</span> <span class="pre">Segmentation</span> <span class="pre">&gt;</span> <span class="pre">Labkit</span></code></p></li>
<li><p>Sucessively add a new label and annotate a single cell instance with the brush tool (always check the <code class="docutils literal notranslate"><span class="pre">override</span></code> option) until <em>all</em> cells are labeled</p></li>
<li><p>Export the label image via <code class="docutils literal notranslate"><span class="pre">Save</span> <span class="pre">Labeling...</span></code> and <code class="docutils literal notranslate"><span class="pre">File</span> <span class="pre">format</span> <span class="pre">&gt;</span> <span class="pre">TIF</span> <span class="pre">Image</span></code></p></li>
</ol>
<p><img alt="https://github.com/mpicbg-csbd/stardist/raw/master/images/labkit_2d_labkit.png" src="https://github.com/mpicbg-csbd/stardist/raw/master/images/labkit_2d_labkit.png" /></p>
<p>Additional tips:</p>
<ul class="simple">
<li><p>The Labkit viewer uses <a class="reference external" href="https://imagej.net/BigDataViewer">BigDataViewer</a> and its keybindings (e.g. <kbd>s</kbd> for contrast options, <kbd>CTRL</kbd>+<kbd>Shift</kbd>+<kbd>mouse-wheel</kbd> for zoom-in/out etc.)</p></li>
<li><p>For 3D images (XYZ) it is best to first convert it to a (XYT) timeseries (via <code class="docutils literal notranslate"><span class="pre">Re-Order</span> <span class="pre">Hyperstack</span></code> and swapping <code class="docutils literal notranslate"><span class="pre">z</span></code> and <code class="docutils literal notranslate"><span class="pre">t</span></code>) and then use <kbd>[</kbd> and <kbd>]</kbd> in Labkit to walk through the slices.</p></li>
</ul>
</div>
<div class="section" id="annotating-with-qupath-2d">
<h3>Annotating with QuPath (2D)<a class="headerlink" href="#annotating-with-qupath-2d" title="Permalink to this headline">¶</a></h3>
<ol class="simple">
<li><p>Install <a class="reference external" href="https://qupath.github.io/">QuPath</a></p></li>
<li><p>Create a new project (<code class="docutils literal notranslate"><span class="pre">File</span> <span class="pre">-&gt;</span> <span class="pre">Project...-&gt;</span> <span class="pre">Create</span> <span class="pre">project</span></code>) and add your raw images</p></li>
<li><p>Annotate nuclei/objects</p></li>
<li><p>Run <a class="reference external" href="https://raw.githubusercontent.com/mpicbg-csbd/stardist/master/extras/qupath_export_annotations.groovy">this script</a> to export the annotations (save the script and drag it on QuPath. Then execute it with <code class="docutils literal notranslate"><span class="pre">Run</span> <span class="pre">for</span> <span class="pre">project</span></code>). The script will create a <code class="docutils literal notranslate"><span class="pre">ground_truth</span></code> folder within your QuPath project that includes both the <code class="docutils literal notranslate"><span class="pre">images</span></code> and <code class="docutils literal notranslate"><span class="pre">masks</span></code> subfolder that then can directly be used with <em>StarDist</em>.</p></li>
</ol>
<p>To see how this could be done, have a look at the following <a class="reference external" href="https://raw.githubusercontent.com/mpicbg-csbd/stardist/master/extras/qupath_example_project.zip">example QuPath project</a> (data courtesy of Romain Guiet, EPFL).</p>
<p><img alt="https://github.com/mpicbg-csbd/stardist/raw/master/images/qupath.png" src="https://github.com/mpicbg-csbd/stardist/raw/master/images/qupath.png" /></p>
</div>
</div>
</div>
<div class="section" id="imagej-fiji-plugin">
<h1>ImageJ/Fiji Plugin<a class="headerlink" href="#imagej-fiji-plugin" title="Permalink to this headline">¶</a></h1>
<p>We currently provide a ImageJ/Fiji plugin that can be used to run pretrained StarDist models on 2D or 2D+time images. Installation and usage instructions can be found at the <a class="reference external" href="https://imagej.net/StarDist">plugin page</a>.</p>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="faq.html" class="btn btn-neutral float-right" title="Frequently Asked Questions (FAQ)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../index.html" class="btn btn-neutral float-left" title="StarDist" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, StarDist docs authors.
      <span class="lastupdated">
        Last updated on Jun 03, 2020.
      </span>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>